# AgentIM — Docker Compose (production-ready)
#
# Quick start:
#   ./deploy.sh           # auto-generates .env and starts all services
#
# Manual start:
#   cp .env.docker.example .env   # fill in secrets
#   docker compose up -d --build
#
# PostgreSQL and Redis are internal — not exposed to the host network.

services:
  postgres:
    image: postgres:18.3-alpine
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?POSTGRES_PASSWORD is required. Run ./deploy.sh or set it in .env}
      POSTGRES_DB: agentim
      # Force PG 18+ to use the legacy data path so the named volume mount works correctly.
      # Without this, PG 18 defaults to /var/lib/postgresql/18/docker which falls outside
      # the pgdata volume, causing data loss on container recreation.
      PGDATA: /var/lib/postgresql/data
    # ports:
    #   - '5432:5432'  # Uncomment for local dev access only; do NOT expose in production
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U postgres']
      interval: 5s
      timeout: 5s
      retries: 5
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'
    networks:
      - internal
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
    restart: unless-stopped

  redis:
    image: redis:8.0-alpine
    # ports:
    #   - '6379:6379'  # Uncomment for local dev access only; do NOT expose in production
    volumes:
      - redisdata:/data
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 5s
      timeout: 5s
      retries: 5
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'
    networks:
      - internal
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    restart: unless-stopped

  server:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    ports:
      - '${PORT:-3000}:3000'
    env_file:
      - path: .env
        required: false
    environment:
      - PORT=3000
      - HOST=0.0.0.0
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD:?POSTGRES_PASSWORD is required}@postgres:5432/agentim
      - REDIS_URL=redis://redis:6379
      - 'JWT_SECRET=${JWT_SECRET:?JWT_SECRET is required. Run ./deploy.sh or set it in .env}'
      - JWT_ACCESS_EXPIRY=${JWT_ACCESS_EXPIRY:-15m}
      - JWT_REFRESH_EXPIRY=${JWT_REFRESH_EXPIRY:-7d}
      - CORS_ORIGIN=${CORS_ORIGIN:-}
      - TRUST_PROXY=${TRUST_PROXY:-false}
      - 'ENCRYPTION_KEY=${ENCRYPTION_KEY:?ENCRYPTION_KEY is required. Run ./deploy.sh or set it in .env}'
      - ADMIN_USERNAME=${ADMIN_USERNAME:-admin}
      - 'ADMIN_PASSWORD=${ADMIN_PASSWORD:?ADMIN_PASSWORD is required. Run ./deploy.sh or set it in .env}'
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        # Use service_started (not service_healthy) because the server supports
        # running without Redis (in-memory fallback). This prevents a Redis
        # health-check failure from blocking server startup entirely.
        condition: service_started
    volumes:
      - uploads_data:/app/uploads
    healthcheck:
      test:
        [
          'CMD-SHELL',
          "wget -qO- http://127.0.0.1:3000/api/health | grep -q '\"ok\":true' || exit 1",
        ]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 15s
    logging:
      driver: json-file
      options:
        max-size: '20m'
        max-file: '5'
    networks:
      - internal
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
    restart: unless-stopped

networks:
  internal:
    driver: bridge

volumes:
  pgdata:
  redisdata:
  uploads_data:
